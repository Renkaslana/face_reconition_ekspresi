# ğŸ—ï¸ System Architecture

Dokumentasi arsitektur lengkap sistem Modern Emotion Detection.

## ğŸ“Š High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     USER INTERFACE LAYER                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  run_demo.py â”‚  â”‚  detect.py   â”‚  â”‚   train.py   â”‚      â”‚
â”‚  â”‚  (Menu GUI)  â”‚  â”‚  (Detection) â”‚  â”‚  (Training)  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                  â”‚                  â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                  â”‚
          â”‚                  â”‚                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         â”‚       BUSINESS LOGIC LAYER          â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         â”‚                  â”‚                  â”‚               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                   â”‚                  â”‚                        â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚            â”‚   utils.py  â”‚    â”‚ config.py  â”‚                â”‚
â”‚            â”‚ (Functions) â”‚    â”‚ (Settings) â”‚                â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                   â”‚                  â”‚                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                  â”‚
                    â”‚                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   â”‚   CORE LAYER     â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   â”‚                  â”‚                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚   TensorFlow/Keras â”‚  â”‚  MediaPipe Face  â”‚               â”‚
â”‚  â”‚   (CNN Model)      â”‚  â”‚    Detection     â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚   OpenCV           â”‚  â”‚  NumPy/sklearn   â”‚               â”‚
â”‚  â”‚   (Image Process)  â”‚  â”‚  (Math/ML Utils) â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Data Flow

### 1ï¸âƒ£ Training Flow
```
Dataset (train/) 
    â†“
[ImageDataGenerator]
    â†“ (Augmentation)
[Training Images] â†’ [CNN Model] â† [Focal Loss + Class Weights]
    â†“
[Model Evaluation]
    â†“
[Save Model] â†’ best_emotion_model.keras
```

### 2ï¸âƒ£ Detection Flow (Webcam)
```
[Webcam/Camera]
    â†“
[Capture Frame]
    â†“
[MediaPipe Face Detection] â† (High Accuracy)
    â†“
[Face Regions Detected]
    â†“
[Preprocess Each Face] â†’ (Resize 48x48, Normalize)
    â†“
[CNN Model Prediction]
    â†“
[Emotion + Confidence]
    â†“
[Draw Bounding Box + Label]
    â†“
[Display Frame] â†’ (with FPS counter)
    â†“
[Loop back to Capture Frame]
```

## ğŸ“¦ Module Dependencies

```
config.py (Configuration)
    â†“ (imported by)
    â”œâ”€â”€ utils.py
    â”œâ”€â”€ train.py
    â””â”€â”€ detect.py

utils.py (Utilities)
    â†“ (imported by)
    â”œâ”€â”€ train.py
    â””â”€â”€ detect.py

train.py (Training)
    â†“ (uses)
    â”œâ”€â”€ config.py
    â”œâ”€â”€ utils.py
    â””â”€â”€ TensorFlow/Keras

detect.py (Detection)
    â†“ (uses)
    â”œâ”€â”€ config.py
    â”œâ”€â”€ utils.py
    â”œâ”€â”€ MediaPipe
    â””â”€â”€ OpenCV
```

## ğŸ§© Component Details

### config.py
```
Purpose: Centralized configuration
Contents:
  â”œâ”€â”€ Dataset paths
  â”œâ”€â”€ Model configuration
  â”œâ”€â”€ Training hyperparameters
  â”œâ”€â”€ Detection settings
  â””â”€â”€ UI settings
```

### utils.py
```
Purpose: Shared utility functions
Functions:
  â”œâ”€â”€ focal_loss() - Custom loss function
  â”œâ”€â”€ calculate_class_weights() - Balance classes
  â”œâ”€â”€ model_exists() - Check model cache
  â”œâ”€â”€ load_model() - Load trained model
  â”œâ”€â”€ preprocess_face() - Prepare face for prediction
  â””â”€â”€ format_prediction() - Format results
```

### train.py
```
Purpose: Model training with caching
Flow:
  1. Check if model exists â†’ Skip if yes
  2. Load and augment data
  3. Calculate class weights
  4. Create CNN model
  5. Train with callbacks
  6. Save best model
  7. Evaluate and log results
```

### detect.py
```
Purpose: Real-time emotion detection
Components:
  â”œâ”€â”€ EmotionDetector class
  â”‚   â”œâ”€â”€ __init__() - Load model + MediaPipe
  â”‚   â”œâ”€â”€ detect_faces() - Find faces (MediaPipe)
  â”‚   â”œâ”€â”€ predict_emotion() - Predict emotion
  â”‚   â”œâ”€â”€ process_frame() - Full pipeline
  â”‚   â”œâ”€â”€ run_webcam() - Webcam mode
  â”‚   â”œâ”€â”€ process_image() - Image mode
  â”‚   â””â”€â”€ process_video() - Video mode
  â””â”€â”€ main() - CLI interface
```

## ğŸ¯ CNN Model Architecture

```
Input: 48x48x1 (Grayscale)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Block 1: Feature Extraction         â”‚
â”‚  Conv2D(64) â†’ BN â†’ Conv2D(64) â†’ BN  â”‚
â”‚  â†’ MaxPool â†’ Dropout(0.25)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ (24x24x64)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Block 2: Feature Extraction         â”‚
â”‚  Conv2D(128) â†’ BN â†’ Conv2D(128) â†’ BNâ”‚
â”‚  â†’ MaxPool â†’ Dropout(0.25)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ (12x12x128)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Block 3: Feature Extraction         â”‚
â”‚  Conv2D(256) â†’ BN â†’ Conv2D(256) â†’ BNâ”‚
â”‚  â†’ MaxPool â†’ Dropout(0.25)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ (6x6x256)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Block 4: High-Level Features        â”‚
â”‚  Conv2D(512) â†’ BN                   â”‚
â”‚  â†’ GlobalAvgPool â†’ Dropout(0.5)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ (512)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Classification Head                 â”‚
â”‚  Dense(512) â†’ BN â†’ Dropout(0.5)     â”‚
â”‚  â†’ Dense(256) â†’ BN â†’ Dropout(0.4)   â”‚
â”‚  â†’ Dense(7) â†’ Softmax               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Output: [7 probabilities] (Emotions)
```

## ğŸ” MediaPipe Face Detection Pipeline

```
Input Frame (BGR)
    â†“
[Convert to RGB]
    â†“
[MediaPipe BlazeFace Model]
    â†“ (Neural Network)
[Face Detections]
    â†“ (for each detection)
[Bounding Box Coordinates]
    â”œâ”€â”€ x, y (top-left)
    â”œâ”€â”€ width
    â””â”€â”€ height
    â†“
[Convert to Absolute Coordinates]
    â†“
[Validate & Clip to Frame]
    â†“
[Return Face Regions]
```

## ğŸš€ Execution Flow

### Scenario 1: First Time Training
```
1. User runs: python train.py
2. Check model exists? â†’ NO
3. Calculate class weights
4. Create data generators
5. Create CNN model
6. Start training (50 epochs)
7. Save best model
8. Done! (Model cached)
```

### Scenario 2: Already Trained
```
1. User runs: python train.py
2. Check model exists? â†’ YES
3. Load model from cache
4. Skip training
5. Done! (30x faster)
```

### Scenario 3: Real-time Detection
```
1. User runs: python detect.py --mode webcam
2. Load trained model
3. Initialize MediaPipe
4. Open webcam
5. LOOP:
   a. Capture frame
   b. Detect faces (MediaPipe)
   c. For each face:
      - Extract region
      - Preprocess (48x48)
      - Predict emotion
      - Draw box + label
   d. Calculate FPS
   e. Display frame
   f. Check key press (Q=quit, S=save)
6. Cleanup & exit
```

## ğŸ’¾ File System Structure

```
/app/
â”‚
â”œâ”€â”€ ğŸ Python Scripts
â”‚   â”œâ”€â”€ config.py         (1 file,  2.2 KB)
â”‚   â”œâ”€â”€ utils.py          (1 file,  6.8 KB)
â”‚   â”œâ”€â”€ train.py          (1 file,  8.2 KB)
â”‚   â”œâ”€â”€ detect.py         (1 file, 15.0 KB)
â”‚   â”œâ”€â”€ run_demo.py       (1 file,  6.0 KB)
â”‚   â””â”€â”€ test_system.py    (1 file,  7.5 KB)
â”‚
â”œâ”€â”€ ğŸ“š Documentation
â”‚   â”œâ”€â”€ README.md         (1 file,  6.5 KB)
â”‚   â”œâ”€â”€ QUICKSTART.md     (1 file,  2.5 KB)
â”‚   â”œâ”€â”€ IMPROVEMENTS.md   (1 file,  9.7 KB)
â”‚   â”œâ”€â”€ SUMMARY.md        (1 file,  8.3 KB)
â”‚   â””â”€â”€ ARCHITECTURE.md   (this file)
â”‚
â”œâ”€â”€ ğŸ“¦ Dependencies
â”‚   â””â”€â”€ requirements.txt  (1 file,  0.3 KB)
â”‚
â”œâ”€â”€ ğŸ’¾ Model & Data
â”‚   â”œâ”€â”€ best_emotion_model.keras  (31 MB)
â”‚   â”œâ”€â”€ train/            (28,709 images, 7 classes)
â”‚   â””â”€â”€ test/             (7,178 images, 7 classes)
â”‚
â””â”€â”€ ğŸ“‚ Generated
    â”œâ”€â”€ models/           (for model versions)
    â”œâ”€â”€ logs/             (training & detection logs)
    â””â”€â”€ screenshots/      (saved screenshots)
```

## ğŸ›ï¸ Configuration Hierarchy

```
config.py (Default Settings)
    â†“
Environment Variables (Optional)
    â†“
Command Line Arguments (Override)
    â†“
Final Configuration Used
```

Example:
```bash
# Use default from config.py
python train.py

# Override with CLI args
python train.py --epochs 100 --batch-size 64

# Environment variable (if supported)
export EMOTION_EPOCHS=100
python train.py
```

## ğŸ” Error Handling Strategy

```
Level 1: Input Validation
  â”œâ”€â”€ Check file exists
  â”œâ”€â”€ Validate parameters
  â””â”€â”€ Verify dependencies

Level 2: Graceful Degradation
  â”œâ”€â”€ Skip invalid frames
  â”œâ”€â”€ Continue on single failure
  â””â”€â”€ Log errors for review

Level 3: Recovery
  â”œâ”€â”€ Retry operations
  â”œâ”€â”€ Fallback mechanisms
  â””â”€â”€ Safe cleanup

Level 4: User Feedback
  â”œâ”€â”€ Clear error messages
  â”œâ”€â”€ Actionable suggestions
  â””â”€â”€ Log file reference
```

## ğŸ“Š Performance Optimization

### Training Optimizations
- âœ… Batch Normalization (stabilize training)
- âœ… Data Augmentation (improve generalization)
- âœ… Early Stopping (prevent overfitting)
- âœ… Learning Rate Scheduling (better convergence)
- âœ… Class Weights (handle imbalance)

### Detection Optimizations
- âœ… Model Caching (no reload every frame)
- âœ… MediaPipe (GPU-accelerated face detection)
- âœ… Batch Prediction (when possible)
- âœ… Frame Skipping (if needed for real-time)
- âœ… Efficient Preprocessing (vectorized operations)

## ğŸ§ª Testing Strategy

```
test_system.py
    â”œâ”€â”€ Import Tests (packages available?)
    â”œâ”€â”€ Config Tests (settings valid?)
    â”œâ”€â”€ Utils Tests (functions work?)
    â”œâ”€â”€ Model Tests (can load?)
    â”œâ”€â”€ MediaPipe Tests (initialized?)
    â”œâ”€â”€ Dataset Tests (data exists?)
    â””â”€â”€ Integration Tests (end-to-end?)
```

## ğŸ“ Design Patterns Used

1. **Separation of Concerns**
   - Config, Utils, Train, Detect separated

2. **Dependency Injection**
   - Pass config to functions, not hardcode

3. **Factory Pattern**
   - Create model, data generators via functions

4. **Singleton Pattern**
   - Logger instance shared

5. **Strategy Pattern**
   - Different detection modes (webcam/image/video)

## ğŸ”„ Version Control

```
Git Structure:
  â”œâ”€â”€ .git/              (version control)
  â”œâ”€â”€ .gitignore         (exclude model, data, logs)
  â””â”€â”€ All source files   (tracked)

Excluded from Git:
  â”œâ”€â”€ best_emotion_model.keras  (too large)
  â”œâ”€â”€ train/             (dataset)
  â”œâ”€â”€ test/              (dataset)
  â”œâ”€â”€ logs/              (runtime logs)
  â””â”€â”€ screenshots/       (user data)
```

## ğŸ¯ Key Architectural Decisions

### âœ… Why Modular Structure?
- Easier to maintain
- Better code reusability
- Easier to test
- Clear responsibilities

### âœ… Why MediaPipe over Haar Cascade?
- Much higher accuracy (95% vs 75%)
- Modern deep learning-based
- GPU-accelerated
- Better multi-angle support

### âœ… Why Auto-Caching?
- Save time (30x faster startup)
- Better user experience
- Efficient resource usage
- Optional force retrain

### âœ… Why CLI + Interactive?
- Flexibility (power users + beginners)
- Scriptable (automation possible)
- User-friendly (menu for beginners)
- Professional (production-ready)

## ğŸ“ˆ Scalability Considerations

### Current System
- âœ… Single model, single camera
- âœ… Real-time processing
- âœ… Local deployment

### Future Extensions
- ğŸ”® Multiple cameras support
- ğŸ”® Distributed processing
- ğŸ”® Cloud deployment
- ğŸ”® API endpoint
- ğŸ”® Mobile app integration

## ğŸ¨ UI/UX Design Philosophy

1. **Simplicity First**
   - One-command execution
   - Clear error messages
   - Intuitive controls

2. **Feedback Loop**
   - FPS counter (performance)
   - Confidence display (trust)
   - Visual feedback (colors)

3. **Progressive Disclosure**
   - Basic: run_demo.py
   - Advanced: CLI with args
   - Expert: Edit config.py

---

**Architecture Status**: âœ… Production Ready

**Terakhir Diperbarui**: 2025-10-07

Made with â¤ï¸ following software engineering best practices

### Contributor
- **Muhammad Affif**
- **Muhamad Fahren Andrean Rangkuti**
- **Putri Areka Sandra**